{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad.nn import Conv2d, BatchNorm2d, Tensor, optim\n",
    "import tinygrad.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "try:\n",
    "  from helpers import get_model_size, estimate_loss, normalize_tensor\n",
    "except ModuleNotFoundError:\n",
    "  import sys\n",
    "  sys.path.append(\"../\")\n",
    "  from helpers import get_model_size, estimate_loss, normalize_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiFaData(Dataset):\n",
    "  def __init__(self, stage=\"train\", transform=None, device=\"cpu\"):\n",
    "    self.device = device\n",
    "    self.base_folder = \"cifar-10-batches-py\"\n",
    "    self.transform = transform\n",
    "    if stage == \"train\":\n",
    "      batch_collection = [f\"data_batch_{i}\" for i in range(1, 5)]\n",
    "    elif stage == \"val\":\n",
    "      batch_collection = [\"data_batch_5\"]\n",
    "    elif stage == \"test\":\n",
    "      batch_collection = [\"test_batch\"]\n",
    "    else:\n",
    "      raise ValueError(\"Invalid stage, choose from train, val, test.\")\n",
    "    self.x_data = []\n",
    "    self.y_data = []\n",
    "    for batch in batch_collection:\n",
    "      with open(f\"../data/cifar-10-batches-py/{batch}\", \"rb\") as f:\n",
    "        data = pickle.load(f, encoding=\"latin1\") \n",
    "        self.x_data.extend(data[\"data\"])\n",
    "        self.y_data.extend(data[\"labels\"])\n",
    "    self.y_data = torch.tensor(self.y_data, device=self.device)\n",
    "    self.x_data = normalize_tensor(torch.tensor(np.vstack(self.x_data).reshape(-1, 3, 32, 32), device=self.device)) # from list to vstack; results in (N, 3, 32, 32)\n",
    "  def __len__(self):\n",
    "    return len(self.y_data)\n",
    "  def __getitem__(self, idx):\n",
    "    if self.transform:\n",
    "      return self.transform(self.x_data[idx]), self.y_data[idx]\n",
    "    return self.x_data[idx], self.y_data[idx]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_ds = CiFaData(stage=\"train\", device=device)\n",
    "val_ds = CiFaData(stage=\"val\", device=device)\n",
    "test_ds = CiFaData(stage=\"test\", device=device)\n",
    "\n",
    "# pinning memory, takes cpu data and pins it to the gpu. meaning if I already \n",
    "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True) \n",
    "val_loader = DataLoader(val_ds, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tinygrad.nn' has no attribute 'Module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModule\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tinygrad.nn' has no attribute 'Module'"
     ]
    }
   ],
   "source": [
    "nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tinygrad.nn' has no attribute 'Module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSubBlock\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModule\u001b[49m):\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, inchannels, outchannels, stride, kernelsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tinygrad.nn' has no attribute 'Module'"
     ]
    }
   ],
   "source": [
    "class SubBlock:\n",
    "  def __init__(self, inchannels, outchannels, stride, kernelsize=3, padding=1):\n",
    "    self.conv1 = Conv2d(in_channels=inchannels, out_channels=outchannels, kernel_size=kernelsize, padding=padding, stride=stride)\n",
    "    self.bnorm1 = BatchNorm2d(outchannels)\n",
    "      nn.ReLU(), # there is no relu module, so this needs to go in the call block ?\n",
    "      nn.Conv2d(in_channels=outchannels, out_channels=outchannels, kernel_size=kernelsize, padding=padding, stride=1),\n",
    "      nn.BatchNorm2d(outchannels)\n",
    "    )\n",
    "  def __call__(self, x):\n",
    "    return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
