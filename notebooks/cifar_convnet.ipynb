{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import trange\n",
    "try:\n",
    "  from helpers import get_model_size, estimate_loss, get_parameters, CiFaData\n",
    "except ModuleNotFoundError:\n",
    "  import sys\n",
    "  sys.path.append(\"../\")\n",
    "  from helpers import get_model_size, estimate_loss, get_parameters, CiFaData\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 256\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.875\n",
    "WEIGHT_DECAY = 0.00125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we actually just need it to download cifar dataset\n",
    "# torchvision.datasets.CIFAR10(train=True, download=True, root='../data/', transform=transforms.ToTensor())\n",
    "# torchvision.datasets.CIFAR10(train=False, download=True, root='../data/', transform=transforms.ToTensor())\n",
    "\n",
    "tf = transforms.Compose([transforms.RandomResizedCrop((32,32)), \n",
    "                         transforms.RandomHorizontalFlip(p=0.58)]) \n",
    "                        #  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# create loader to get the params\n",
    "# complete_ds = CiFaData(stage=\"all\")\n",
    "# big_loader = DataLoader(complete_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=14)\n",
    "# params = get_parameters(big_loader)\n",
    "\n",
    "params = torch.tensor([0.4919, 0.4827, 0.4472]), torch.tensor([0.2470, 0.2434, 0.2616])\n",
    "print(f\"normalized parameters of the dataset: {params}\")\n",
    "\n",
    "train_ds = CiFaData(stage=\"train\", transform=tf, dataset_params=params)\n",
    "val_ds = CiFaData(stage=\"val\", dataset_params=params)\n",
    "test_ds = CiFaData(stage=\"test\", dataset_params=params)\n",
    "\n",
    "# pinning memory, takes cpu data and pins it to the gpu.\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=14, pin_memory=True) \n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=14, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=14, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the paper: \n",
    "# We adopt batch normalization (BN) [16] right after each convolution and\n",
    "# before activation, following [16].\n",
    "\n",
    "class PrepBlock(nn.Module):\n",
    "  # fixed channels for cifar\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.prep_block = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    return self.prep_block(x)\n",
    "  def init_weights(self):\n",
    "    for layer in self.prep_block:\n",
    "      if isinstance(layer, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if layer.bias is not None:\n",
    "          layer.bias.data.zero_()\n",
    "\n",
    "class ComputeBlock(nn.Module):\n",
    "  def __init__(self, inchannels, outchannels, stride, downsample=None):\n",
    "    super().__init__()\n",
    "    self.convblock = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=inchannels, out_channels=outchannels, kernel_size=3, padding=1, stride=stride, bias=False),\n",
    "      nn.BatchNorm2d(outchannels),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(in_channels=outchannels, out_channels=outchannels, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "      nn.BatchNorm2d(outchannels)\n",
    "    )\n",
    "    self.downsample = downsample\n",
    "    if not inchannels == outchannels:\n",
    "      self.downsample = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=inchannels, out_channels=outchannels, kernel_size=1, stride=2, bias=False),\n",
    "        nn.BatchNorm2d(outchannels)\n",
    "      )\n",
    "    self.relu = nn.ReLU()\n",
    "  def forward(self, x):\n",
    "    x_skip = x \n",
    "    x = self.convblock(x)\n",
    "    if self.downsample:\n",
    "      x_skip = self.downsample(x_skip)\n",
    "    out = self.relu(x+x_skip)\n",
    "    return out\n",
    "  def init_weights(self):\n",
    "    for layer in self.convblock:\n",
    "      if isinstance(layer, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if layer.bias is not None:\n",
    "          layer.bias.data.zero_()\n",
    "    if self.downsample:\n",
    "      for layer in self.downsample:\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "          nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "          if layer.bias is not None:\n",
    "            layer.bias.data.zero_()\n",
    "  \n",
    "class ResNet18New(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.resnet = nn.Sequential(\n",
    "      PrepBlock(), # (B,64,8,8)\n",
    "      ComputeBlock(64, 64, stride=1), # (B,64,8,8)\n",
    "      ComputeBlock(64,128, stride=2), # (B,128,4,4)\n",
    "      ComputeBlock(128,256, stride=2), # (B,256,2,2)\n",
    "      ComputeBlock(256, 512, stride=2), # (B,512,1,1)\n",
    "      nn.AdaptiveAvgPool2d((1,1)),\n",
    "      nn.Flatten(start_dim=1), # (B,512)\n",
    "      nn.Linear(512, 10) # (B, 10)\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    return self.resnet(x)\n",
    "  def init_weights(self):\n",
    "    for module in self.modules():\n",
    "      if isinstance(module, ComputeBlock):\n",
    "        module.init_weights()\n",
    "      elif isinstance(module, PrepBlock):\n",
    "        module.init_weights()\n",
    "      elif isinstance(module, nn.Linear):\n",
    "        nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18New()\n",
    "model.init_weights()\n",
    "model.to(device)\n",
    "\n",
    "# optimizer = optim.AdamW(params=[p for p in model.parameters() if p.requires_grad==True], lr=lr)\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY, momentum=MOMENTUM)\n",
    "scheduler = lr_scheduler.StepLR(optimizer=optimizer, step_size=5, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_size = get_model_size(model)\n",
    "\n",
    "# training loop\n",
    "losses = []\n",
    "raw_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for i in (t:=trange(EPOCHS)):\n",
    "  model.train()\n",
    "  epoch_loss = []\n",
    "  for step, (x, y) in enumerate(train_loader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    predictions = model(x)\n",
    "    loss = criterion(predictions, y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    raw_losses.append(loss.item())\n",
    "    epoch_loss.append(loss.item())\n",
    "\n",
    "  # only one per iteration\n",
    "  losses.append(np.mean(epoch_loss))\n",
    "  val_loss, val_acc = estimate_loss(model, val_loader, criterion, device)\n",
    "  val_losses.append(val_loss)\n",
    "  # scheduler.step()\n",
    "  t.set_description(f\"epoch {i+1} | training loss: {losses[-1]:.4f} | validation loss: {val_losses[-1]:.4f} | current lr: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "  \n",
    "# test_loss = estimate_loss(model, test_loader, criterion, device) \n",
    "# print(f'test loss : {test_loss}')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'batchnorm  lr={LR}')\n",
    "plt.plot(range(EPOCHS), losses, label='training')\n",
    "plt.plot(range(EPOCHS), val_losses, label='validation')\n",
    "plt.plot(range(EPOCHS), [np.min(val_losses)]*EPOCHS, color='r', label=f'minimum val loss at epoch {np.argmin(val_losses)+1}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the graph\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"torchlogs/\")\n",
    "writer.add_graph(model, x)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/cifar-10-batches-py/batches.meta', 'rb') as f:\n",
    "  meta = pickle.load(f)\n",
    "meta['label_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 9\n",
    "input_ = x[n].cpu().permute(1,2,0).numpy()\n",
    "\n",
    "plt.title(meta['label_names'][y[n]])\n",
    "plt.imshow(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todos:\n",
    "## extract feature detection layers\n",
    "## increase size: make a resnet 50\n",
    "### add bottlenecks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize feature maps\n",
    "\n",
    "we can loop over the elements with model.children() or just address individual layers like:\n",
    "model.block0[n]; you can go down until you hit a 'Sequential' block and then go on slicing\n",
    "\n",
    "\n",
    "seems like a good guide: \n",
    "https://ravivaishnav20.medium.com/visualizing-feature-maps-using-pytorch-12a48cd1e573"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = res18.block4.block[1].block[0].weight.detach().clone()\n",
    "print(weights.shape)\n",
    "weights = normalize_tensor(weights)\n",
    "filter_img = torchvision.utils.make_grid(weights, nrow=int(np.sqrt(weights.shape[0])))\n",
    "plt.imshow(filter_img.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visTensor(tensor, ch=0, allkernels=False, nrow=8, padding=1): \n",
    "    n,c,w,h = tensor.shape\n",
    "\n",
    "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
    "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
    "\n",
    "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
    "    grid = torchvision.utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    plt.figure( figsize=(nrow,rows) )\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = res18.block0[0].weight.detach().clone()\n",
    "visTensor(layer)\n",
    "plt.axis('off')\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_block = res18.block0[0].weight.detach().clone()\n",
    "first_block = res18.block1.block[0].weight.detach.clone()\n",
    "print(first_block.shape)\n",
    "first_block =normalize_tensor(first_block)\n",
    "filter_img = torchvision.utils.make_grid(first_block, nrow=int(np.sqrt(first_block.shape[0])))\n",
    "plt.axis('off')\n",
    "plt.ioff()\n",
    "plt.imshow(filter_img.permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "conv_layers = []\n",
    "\n",
    "model_children = list(res18.children())\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for i in range(len(model_children)):\n",
    "  # this only counts the shape shifter-convs! - need to go into the sub blocks\n",
    "  if type(model_children[i]) == nn.Conv2d:\n",
    "    cnt +=1\n",
    "\n",
    "print(cnt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "bcb690d7a096d114b5411ea453cbe6506dfb4402b1a4c8888831b78b4b26966d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
